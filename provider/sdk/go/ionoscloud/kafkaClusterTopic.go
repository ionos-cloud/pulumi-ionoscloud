// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package ionoscloud

import (
	"context"
	"reflect"

	"errors"
	"github.com/ionos-cloud/pulumi-ionoscloud/sdk/go/ionoscloud/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

type KafkaClusterTopic struct {
	pulumi.CustomResourceState

	// The ID of the Kafka Cluster to which the topic belongs.
	ClusterId pulumi.StringOutput `pulumi:"clusterId"`
	// The location of your Kafka Cluster Topic. Supported locations: de/fra, de/txl
	Location pulumi.StringOutput `pulumi:"location"`
	// The name of your Kafka Cluster Topic. Must be 63 characters or less and must begin and end with an alphanumeric
	// character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
	Name pulumi.StringOutput `pulumi:"name"`
	// The number of partitions of the topic. Partitions allow for parallel processing of messages. The partition count must be
	// greater than or equal to the replication factor.
	NumberOfPartitions pulumi.IntPtrOutput `pulumi:"numberOfPartitions"`
	// The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on
	// different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka Cluster.
	ReplicationFactor pulumi.IntPtrOutput `pulumi:"replicationFactor"`
	// This configuration controls the maximum time we will retain a log before we will discard old log segments to free up
	// space. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied.
	RetentionTime pulumi.IntPtrOutput `pulumi:"retentionTime"`
	// This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so
	// a larger segment size means fewer files but less granular control over retention.
	SegmentBytes pulumi.IntPtrOutput `pulumi:"segmentBytes"`
}

// NewKafkaClusterTopic registers a new resource with the given unique name, arguments, and options.
func NewKafkaClusterTopic(ctx *pulumi.Context,
	name string, args *KafkaClusterTopicArgs, opts ...pulumi.ResourceOption) (*KafkaClusterTopic, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.ClusterId == nil {
		return nil, errors.New("invalid value for required argument 'ClusterId'")
	}
	if args.Location == nil {
		return nil, errors.New("invalid value for required argument 'Location'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource KafkaClusterTopic
	err := ctx.RegisterResource("ionoscloud:index/kafkaClusterTopic:KafkaClusterTopic", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetKafkaClusterTopic gets an existing KafkaClusterTopic resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetKafkaClusterTopic(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *KafkaClusterTopicState, opts ...pulumi.ResourceOption) (*KafkaClusterTopic, error) {
	var resource KafkaClusterTopic
	err := ctx.ReadResource("ionoscloud:index/kafkaClusterTopic:KafkaClusterTopic", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering KafkaClusterTopic resources.
type kafkaClusterTopicState struct {
	// The ID of the Kafka Cluster to which the topic belongs.
	ClusterId *string `pulumi:"clusterId"`
	// The location of your Kafka Cluster Topic. Supported locations: de/fra, de/txl
	Location *string `pulumi:"location"`
	// The name of your Kafka Cluster Topic. Must be 63 characters or less and must begin and end with an alphanumeric
	// character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
	Name *string `pulumi:"name"`
	// The number of partitions of the topic. Partitions allow for parallel processing of messages. The partition count must be
	// greater than or equal to the replication factor.
	NumberOfPartitions *int `pulumi:"numberOfPartitions"`
	// The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on
	// different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka Cluster.
	ReplicationFactor *int `pulumi:"replicationFactor"`
	// This configuration controls the maximum time we will retain a log before we will discard old log segments to free up
	// space. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied.
	RetentionTime *int `pulumi:"retentionTime"`
	// This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so
	// a larger segment size means fewer files but less granular control over retention.
	SegmentBytes *int `pulumi:"segmentBytes"`
}

type KafkaClusterTopicState struct {
	// The ID of the Kafka Cluster to which the topic belongs.
	ClusterId pulumi.StringPtrInput
	// The location of your Kafka Cluster Topic. Supported locations: de/fra, de/txl
	Location pulumi.StringPtrInput
	// The name of your Kafka Cluster Topic. Must be 63 characters or less and must begin and end with an alphanumeric
	// character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
	Name pulumi.StringPtrInput
	// The number of partitions of the topic. Partitions allow for parallel processing of messages. The partition count must be
	// greater than or equal to the replication factor.
	NumberOfPartitions pulumi.IntPtrInput
	// The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on
	// different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka Cluster.
	ReplicationFactor pulumi.IntPtrInput
	// This configuration controls the maximum time we will retain a log before we will discard old log segments to free up
	// space. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied.
	RetentionTime pulumi.IntPtrInput
	// This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so
	// a larger segment size means fewer files but less granular control over retention.
	SegmentBytes pulumi.IntPtrInput
}

func (KafkaClusterTopicState) ElementType() reflect.Type {
	return reflect.TypeOf((*kafkaClusterTopicState)(nil)).Elem()
}

type kafkaClusterTopicArgs struct {
	// The ID of the Kafka Cluster to which the topic belongs.
	ClusterId string `pulumi:"clusterId"`
	// The location of your Kafka Cluster Topic. Supported locations: de/fra, de/txl
	Location string `pulumi:"location"`
	// The name of your Kafka Cluster Topic. Must be 63 characters or less and must begin and end with an alphanumeric
	// character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
	Name *string `pulumi:"name"`
	// The number of partitions of the topic. Partitions allow for parallel processing of messages. The partition count must be
	// greater than or equal to the replication factor.
	NumberOfPartitions *int `pulumi:"numberOfPartitions"`
	// The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on
	// different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka Cluster.
	ReplicationFactor *int `pulumi:"replicationFactor"`
	// This configuration controls the maximum time we will retain a log before we will discard old log segments to free up
	// space. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied.
	RetentionTime *int `pulumi:"retentionTime"`
	// This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so
	// a larger segment size means fewer files but less granular control over retention.
	SegmentBytes *int `pulumi:"segmentBytes"`
}

// The set of arguments for constructing a KafkaClusterTopic resource.
type KafkaClusterTopicArgs struct {
	// The ID of the Kafka Cluster to which the topic belongs.
	ClusterId pulumi.StringInput
	// The location of your Kafka Cluster Topic. Supported locations: de/fra, de/txl
	Location pulumi.StringInput
	// The name of your Kafka Cluster Topic. Must be 63 characters or less and must begin and end with an alphanumeric
	// character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
	Name pulumi.StringPtrInput
	// The number of partitions of the topic. Partitions allow for parallel processing of messages. The partition count must be
	// greater than or equal to the replication factor.
	NumberOfPartitions pulumi.IntPtrInput
	// The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on
	// different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka Cluster.
	ReplicationFactor pulumi.IntPtrInput
	// This configuration controls the maximum time we will retain a log before we will discard old log segments to free up
	// space. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied.
	RetentionTime pulumi.IntPtrInput
	// This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so
	// a larger segment size means fewer files but less granular control over retention.
	SegmentBytes pulumi.IntPtrInput
}

func (KafkaClusterTopicArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*kafkaClusterTopicArgs)(nil)).Elem()
}

type KafkaClusterTopicInput interface {
	pulumi.Input

	ToKafkaClusterTopicOutput() KafkaClusterTopicOutput
	ToKafkaClusterTopicOutputWithContext(ctx context.Context) KafkaClusterTopicOutput
}

func (*KafkaClusterTopic) ElementType() reflect.Type {
	return reflect.TypeOf((**KafkaClusterTopic)(nil)).Elem()
}

func (i *KafkaClusterTopic) ToKafkaClusterTopicOutput() KafkaClusterTopicOutput {
	return i.ToKafkaClusterTopicOutputWithContext(context.Background())
}

func (i *KafkaClusterTopic) ToKafkaClusterTopicOutputWithContext(ctx context.Context) KafkaClusterTopicOutput {
	return pulumi.ToOutputWithContext(ctx, i).(KafkaClusterTopicOutput)
}

// KafkaClusterTopicArrayInput is an input type that accepts KafkaClusterTopicArray and KafkaClusterTopicArrayOutput values.
// You can construct a concrete instance of `KafkaClusterTopicArrayInput` via:
//
//	KafkaClusterTopicArray{ KafkaClusterTopicArgs{...} }
type KafkaClusterTopicArrayInput interface {
	pulumi.Input

	ToKafkaClusterTopicArrayOutput() KafkaClusterTopicArrayOutput
	ToKafkaClusterTopicArrayOutputWithContext(context.Context) KafkaClusterTopicArrayOutput
}

type KafkaClusterTopicArray []KafkaClusterTopicInput

func (KafkaClusterTopicArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*KafkaClusterTopic)(nil)).Elem()
}

func (i KafkaClusterTopicArray) ToKafkaClusterTopicArrayOutput() KafkaClusterTopicArrayOutput {
	return i.ToKafkaClusterTopicArrayOutputWithContext(context.Background())
}

func (i KafkaClusterTopicArray) ToKafkaClusterTopicArrayOutputWithContext(ctx context.Context) KafkaClusterTopicArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(KafkaClusterTopicArrayOutput)
}

// KafkaClusterTopicMapInput is an input type that accepts KafkaClusterTopicMap and KafkaClusterTopicMapOutput values.
// You can construct a concrete instance of `KafkaClusterTopicMapInput` via:
//
//	KafkaClusterTopicMap{ "key": KafkaClusterTopicArgs{...} }
type KafkaClusterTopicMapInput interface {
	pulumi.Input

	ToKafkaClusterTopicMapOutput() KafkaClusterTopicMapOutput
	ToKafkaClusterTopicMapOutputWithContext(context.Context) KafkaClusterTopicMapOutput
}

type KafkaClusterTopicMap map[string]KafkaClusterTopicInput

func (KafkaClusterTopicMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*KafkaClusterTopic)(nil)).Elem()
}

func (i KafkaClusterTopicMap) ToKafkaClusterTopicMapOutput() KafkaClusterTopicMapOutput {
	return i.ToKafkaClusterTopicMapOutputWithContext(context.Background())
}

func (i KafkaClusterTopicMap) ToKafkaClusterTopicMapOutputWithContext(ctx context.Context) KafkaClusterTopicMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(KafkaClusterTopicMapOutput)
}

type KafkaClusterTopicOutput struct{ *pulumi.OutputState }

func (KafkaClusterTopicOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**KafkaClusterTopic)(nil)).Elem()
}

func (o KafkaClusterTopicOutput) ToKafkaClusterTopicOutput() KafkaClusterTopicOutput {
	return o
}

func (o KafkaClusterTopicOutput) ToKafkaClusterTopicOutputWithContext(ctx context.Context) KafkaClusterTopicOutput {
	return o
}

// The ID of the Kafka Cluster to which the topic belongs.
func (o KafkaClusterTopicOutput) ClusterId() pulumi.StringOutput {
	return o.ApplyT(func(v *KafkaClusterTopic) pulumi.StringOutput { return v.ClusterId }).(pulumi.StringOutput)
}

// The location of your Kafka Cluster Topic. Supported locations: de/fra, de/txl
func (o KafkaClusterTopicOutput) Location() pulumi.StringOutput {
	return o.ApplyT(func(v *KafkaClusterTopic) pulumi.StringOutput { return v.Location }).(pulumi.StringOutput)
}

// The name of your Kafka Cluster Topic. Must be 63 characters or less and must begin and end with an alphanumeric
// character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
func (o KafkaClusterTopicOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *KafkaClusterTopic) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// The number of partitions of the topic. Partitions allow for parallel processing of messages. The partition count must be
// greater than or equal to the replication factor.
func (o KafkaClusterTopicOutput) NumberOfPartitions() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *KafkaClusterTopic) pulumi.IntPtrOutput { return v.NumberOfPartitions }).(pulumi.IntPtrOutput)
}

// The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on
// different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka Cluster.
func (o KafkaClusterTopicOutput) ReplicationFactor() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *KafkaClusterTopic) pulumi.IntPtrOutput { return v.ReplicationFactor }).(pulumi.IntPtrOutput)
}

// This configuration controls the maximum time we will retain a log before we will discard old log segments to free up
// space. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied.
func (o KafkaClusterTopicOutput) RetentionTime() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *KafkaClusterTopic) pulumi.IntPtrOutput { return v.RetentionTime }).(pulumi.IntPtrOutput)
}

// This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so
// a larger segment size means fewer files but less granular control over retention.
func (o KafkaClusterTopicOutput) SegmentBytes() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *KafkaClusterTopic) pulumi.IntPtrOutput { return v.SegmentBytes }).(pulumi.IntPtrOutput)
}

type KafkaClusterTopicArrayOutput struct{ *pulumi.OutputState }

func (KafkaClusterTopicArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*KafkaClusterTopic)(nil)).Elem()
}

func (o KafkaClusterTopicArrayOutput) ToKafkaClusterTopicArrayOutput() KafkaClusterTopicArrayOutput {
	return o
}

func (o KafkaClusterTopicArrayOutput) ToKafkaClusterTopicArrayOutputWithContext(ctx context.Context) KafkaClusterTopicArrayOutput {
	return o
}

func (o KafkaClusterTopicArrayOutput) Index(i pulumi.IntInput) KafkaClusterTopicOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *KafkaClusterTopic {
		return vs[0].([]*KafkaClusterTopic)[vs[1].(int)]
	}).(KafkaClusterTopicOutput)
}

type KafkaClusterTopicMapOutput struct{ *pulumi.OutputState }

func (KafkaClusterTopicMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*KafkaClusterTopic)(nil)).Elem()
}

func (o KafkaClusterTopicMapOutput) ToKafkaClusterTopicMapOutput() KafkaClusterTopicMapOutput {
	return o
}

func (o KafkaClusterTopicMapOutput) ToKafkaClusterTopicMapOutputWithContext(ctx context.Context) KafkaClusterTopicMapOutput {
	return o
}

func (o KafkaClusterTopicMapOutput) MapIndex(k pulumi.StringInput) KafkaClusterTopicOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *KafkaClusterTopic {
		return vs[0].(map[string]*KafkaClusterTopic)[vs[1].(string)]
	}).(KafkaClusterTopicOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*KafkaClusterTopicInput)(nil)).Elem(), &KafkaClusterTopic{})
	pulumi.RegisterInputType(reflect.TypeOf((*KafkaClusterTopicArrayInput)(nil)).Elem(), KafkaClusterTopicArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*KafkaClusterTopicMapInput)(nil)).Elem(), KafkaClusterTopicMap{})
	pulumi.RegisterOutputType(KafkaClusterTopicOutput{})
	pulumi.RegisterOutputType(KafkaClusterTopicArrayOutput{})
	pulumi.RegisterOutputType(KafkaClusterTopicMapOutput{})
}
