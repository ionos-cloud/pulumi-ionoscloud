// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Ionoscloud.Kafka
{
    /// <summary>
    /// Manages a **Kafka Cluster Topic** on IonosCloud.
    /// 
    /// ## Example Usage
    /// 
    /// This resource will create an operational Kafka Cluster Topic. After this section completes, the provisioner can be
    /// called.
    /// 
    /// &lt;!--Start PulumiCodeChooser --&gt;
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Ionoscloud = Pulumi.Ionoscloud;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     // Basic example
    ///     var exampleDatacenter = new Ionoscloud.Compute.Datacenter("exampleDatacenter", new()
    ///     {
    ///         Location = "de/fra",
    ///     });
    /// 
    ///     var exampleLan = new Ionoscloud.Compute.Lan("exampleLan", new()
    ///     {
    ///         DatacenterId = exampleDatacenter.Id,
    ///         Public = false,
    ///     });
    /// 
    ///     var exampleCluster = new Ionoscloud.Kafka.Cluster("exampleCluster", new()
    ///     {
    ///         Location = exampleDatacenter.Location,
    ///         Version = "3.7.0",
    ///         Size = "S",
    ///         Connections = new Ionoscloud.Kafka.Inputs.ClusterConnectionsArgs
    ///         {
    ///             DatacenterId = exampleDatacenter.Id,
    ///             LanId = exampleLan.Id,
    ///             BrokerAddresses = new[]
    ///             {
    ///                 "192.168.1.101/24",
    ///                 "192.168.1.102/24",
    ///                 "192.168.1.103/24",
    ///             },
    ///         },
    ///     });
    /// 
    ///     var exampleTopic = new Ionoscloud.Kafka.Topic("exampleTopic", new()
    ///     {
    ///         ClusterId = exampleCluster.Id,
    ///         Location = exampleCluster.Location,
    ///         ReplicationFactor = 1,
    ///         NumberOfPartitions = 1,
    ///         RetentionTime = 86400000,
    ///         SegmentBytes = 1073741824,
    ///     });
    /// 
    /// });
    /// ```
    /// &lt;!--End PulumiCodeChooser --&gt;
    /// 
    /// ## Import
    /// 
    /// Kafka Cluster Topic can be imported using the `location`, `kafka cluster id` and the `kafka cluster topic id`:
    /// 
    /// ```sh
    /// $ pulumi import ionoscloud:kafka/topic:Topic my_topic {location}:{kafka cluster uuid}:{kafka cluster topic uuid}
    /// ```
    /// </summary>
    [IonoscloudResourceType("ionoscloud:kafka/topic:Topic")]
    public partial class Topic : global::Pulumi.CustomResource
    {
        /// <summary>
        /// [string] ID of the Kafka Cluster that the topic belongs to.
        /// </summary>
        [Output("clusterId")]
        public Output<string> ClusterId { get; private set; } = null!;

        /// <summary>
        /// [string] The location of the Kafka Cluster Topic. Possible values: `de/fra`, `de/txl`
        /// </summary>
        [Output("location")]
        public Output<string> Location { get; private set; } = null!;

        /// <summary>
        /// [string] Name of the Kafka Cluster.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// [int] The number of partitions of the topic. Partitions allow for parallel
        /// processing of messages. The partition count must be greater than or equal to the replication factor. Minimum value: 1.
        /// Default value: 3.
        /// </summary>
        [Output("numberOfPartitions")]
        public Output<int?> NumberOfPartitions { get; private set; } = null!;

        /// <summary>
        /// [int] The number of replicas of the topic. The replication factor determines how many
        /// copies of the topic are stored on different brokers. The replication factor must be less than or equal to the number
        /// of brokers in the Kafka Cluster. Minimum value: 1. Default value: 3.
        /// </summary>
        [Output("replicationFactor")]
        public Output<int?> ReplicationFactor { get; private set; } = null!;

        /// <summary>
        /// [int] This configuration controls the maximum time we will retain a log before we will
        /// discard old log segments to free up space. This represents an SLA on how soon consumers must read their data. If set
        /// to -1, no time limit is applied. Default value: 604800000.
        /// </summary>
        [Output("retentionTime")]
        public Output<int?> RetentionTime { get; private set; } = null!;

        /// <summary>
        /// [int] This configuration controls the segment file size for the log. Retention and
        /// cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over
        /// retention. Default value: 1073741824.
        /// </summary>
        [Output("segmentBytes")]
        public Output<int?> SegmentBytes { get; private set; } = null!;


        /// <summary>
        /// Create a Topic resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public Topic(string name, TopicArgs args, CustomResourceOptions? options = null)
            : base("ionoscloud:kafka/topic:Topic", name, args ?? new TopicArgs(), MakeResourceOptions(options, ""))
        {
        }

        private Topic(string name, Input<string> id, TopicState? state = null, CustomResourceOptions? options = null)
            : base("ionoscloud:kafka/topic:Topic", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing Topic resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static Topic Get(string name, Input<string> id, TopicState? state = null, CustomResourceOptions? options = null)
        {
            return new Topic(name, id, state, options);
        }
    }

    public sealed class TopicArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// [string] ID of the Kafka Cluster that the topic belongs to.
        /// </summary>
        [Input("clusterId", required: true)]
        public Input<string> ClusterId { get; set; } = null!;

        /// <summary>
        /// [string] The location of the Kafka Cluster Topic. Possible values: `de/fra`, `de/txl`
        /// </summary>
        [Input("location", required: true)]
        public Input<string> Location { get; set; } = null!;

        /// <summary>
        /// [string] Name of the Kafka Cluster.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// [int] The number of partitions of the topic. Partitions allow for parallel
        /// processing of messages. The partition count must be greater than or equal to the replication factor. Minimum value: 1.
        /// Default value: 3.
        /// </summary>
        [Input("numberOfPartitions")]
        public Input<int>? NumberOfPartitions { get; set; }

        /// <summary>
        /// [int] The number of replicas of the topic. The replication factor determines how many
        /// copies of the topic are stored on different brokers. The replication factor must be less than or equal to the number
        /// of brokers in the Kafka Cluster. Minimum value: 1. Default value: 3.
        /// </summary>
        [Input("replicationFactor")]
        public Input<int>? ReplicationFactor { get; set; }

        /// <summary>
        /// [int] This configuration controls the maximum time we will retain a log before we will
        /// discard old log segments to free up space. This represents an SLA on how soon consumers must read their data. If set
        /// to -1, no time limit is applied. Default value: 604800000.
        /// </summary>
        [Input("retentionTime")]
        public Input<int>? RetentionTime { get; set; }

        /// <summary>
        /// [int] This configuration controls the segment file size for the log. Retention and
        /// cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over
        /// retention. Default value: 1073741824.
        /// </summary>
        [Input("segmentBytes")]
        public Input<int>? SegmentBytes { get; set; }

        public TopicArgs()
        {
        }
        public static new TopicArgs Empty => new TopicArgs();
    }

    public sealed class TopicState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// [string] ID of the Kafka Cluster that the topic belongs to.
        /// </summary>
        [Input("clusterId")]
        public Input<string>? ClusterId { get; set; }

        /// <summary>
        /// [string] The location of the Kafka Cluster Topic. Possible values: `de/fra`, `de/txl`
        /// </summary>
        [Input("location")]
        public Input<string>? Location { get; set; }

        /// <summary>
        /// [string] Name of the Kafka Cluster.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// [int] The number of partitions of the topic. Partitions allow for parallel
        /// processing of messages. The partition count must be greater than or equal to the replication factor. Minimum value: 1.
        /// Default value: 3.
        /// </summary>
        [Input("numberOfPartitions")]
        public Input<int>? NumberOfPartitions { get; set; }

        /// <summary>
        /// [int] The number of replicas of the topic. The replication factor determines how many
        /// copies of the topic are stored on different brokers. The replication factor must be less than or equal to the number
        /// of brokers in the Kafka Cluster. Minimum value: 1. Default value: 3.
        /// </summary>
        [Input("replicationFactor")]
        public Input<int>? ReplicationFactor { get; set; }

        /// <summary>
        /// [int] This configuration controls the maximum time we will retain a log before we will
        /// discard old log segments to free up space. This represents an SLA on how soon consumers must read their data. If set
        /// to -1, no time limit is applied. Default value: 604800000.
        /// </summary>
        [Input("retentionTime")]
        public Input<int>? RetentionTime { get; set; }

        /// <summary>
        /// [int] This configuration controls the segment file size for the log. Retention and
        /// cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over
        /// retention. Default value: 1073741824.
        /// </summary>
        [Input("segmentBytes")]
        public Input<int>? SegmentBytes { get; set; }

        public TopicState()
        {
        }
        public static new TopicState Empty => new TopicState();
    }
}
